
1.How to launcher Tensorboard
import tensorflow as tf  
with tf.name_scope('input1'):  
    input1 = tf.constant([1.0,2.0,3.0],name="input1")  
with tf.name_scope('input2'):  
    input2 = tf.Variable(tf.random_uniform([3]),name="input2")  
output = tf.add_n([input1,input2],name="add")  
writer = tf.summary.FileWriter("/path/to/log",tf.get_default_graph())  
writer.close()

cmd输入tensorboard --logdir =/path/to/log ( 具体文件路径名，与代码中路径保持一致即可)
弹出和tensorboard路径
打开浏览器：输入该路径即可。点击GRAPH

2.Tensorflow
  add/sub/multiply/div/truediv/floordiv/mod/pow
  less/less_equal/greater/greater
  logical_and/logical_or/logical_xor
  
  use default graph
  also_in_default_graph=tf.sub(5,1)
  default_graph=tf.get_default_graph()
  
  create new graph not default graph:
  g1=tf.Graph()
  with g1.as_default():
    
  get handle to default graph
  g1=tf.get_default_graph()
  g2=tf.Graph()
  with g1.as_default():
      #define g1 operations here.
      
  with g2.as_default():
      #define g2 operations here.
      
  Graph.as_graph_def() and tf.import_graph_def
  
  Sessions:
    the two calls are identical
    sess=tf.Session()
    sess=tf.Session(graph=tf.get_default_graph())
    
    Fetches:
      sess.run([a,b]) # returns [2,3]
      fetch is a list,output of run will be a list
      
    Operation.run() or Tensor.eval()
    
    input_dict={a:np.array([5,3],dtype=np.int32)}
    sess.run(d,feed_dict=input_dict)
    
    Variables
     my_var=tf.Variable(3,name="my_variable")
     add=tf.add(3,my_var)
     tf.zeros/ones/random_normal/random_uniform/truncated_normal
     trunc=tf.truncated_normal([2,2],mean=5.0,stddev=1.0)
     
     
     Variables Initialization:
       1.init=tf.initialize_all_variables()
         sess=tf.Session()
         sess.run(init)
         
       2.var1=tf.Variable(0,name="initialize_me")
        init=tf.initialize_variables([var1],name="init_var1")
        sess=tf.Session()
        sess.run(init)
        
      Viriables Changing:
           my_var=tf.Variable(1)
           my_var_times_two=my_car.assign(my_car*2)
           assign_add/assign_sub  only for increment or decrement
      
      organize your graph with name scopes:
        with tf.name_scope("scope_a"):
            a=tf.add(1,2,name="a_add")
            b=tf.mul(a,3,name="a_mul")
            
        with tf.name_scope("scope_b"):
            c=tf.add(1,2,name="b_add")
            d=tf.mul(c,3,name="b_mul")
      
        e=tf.add(b,d,name="output")
        writer=tf.train.SummaryWriter('./path',graph=tf.get_default_graph())
        writer.close()
        
        tensorboard --logdir='./path'

    Save training checkpoint
       saver=tf.train.Saver()
       saver.save(sess,"my-model",global_step=step)
       
    recovery from saver file:
      ckpt=tf.train.get_checkpoint_state(os.path.dirname(__file__))
      if ckpt and cpkt.model_checkpoint_path:
         saver.restore(sess,model_checkpoint_path)
         initial_step=int(ckpt.model_checkpoint_path.rsplit('-',1)[1])
         for step in range(initial_step,training_step)
            ...

  For instance:
    1.linear regression:
      W=tf.Variable(tf.zeros([2,1]),name="weight")
      b=tf.Variable(0,name="bias")
      def inference(X):
         return tf.matmul(X,w)+b
      def loss(X,y):
         Y_pred=inference(X)
         return tf.reduce_sum(tf.squared_difference(Y,Y_predicted))
      def inputs():
         weight_age=[[84,46],[73,20],[65,52],[70,30],[76,57],[69,25],[63,28],[72,36],[79,57],[75,44],[27,24],[89,31],[65,52]]
         blood_fat_content=[354,190,405,263,451,302,288,385,402,365]
         return tf.to_float(weight_age),tf.to_float(blood_fat_content)
      def train(total_loss):
         learning_rate=0.0000001
         return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)
      def evaluate(sess,X,y):
         print sess.run(inference([[80,25.]])) ~303
         print sess.run(inference([[65,25.]])) ~256
         
   2.Logistic regression
      W=tf.Variable(tf.zeros([5,1]),name="weight")
      b=tf.Variable(0,name="bias")
      def conbine_input(X):
         return tf.matmul(X,w)+b
      def inputs():
        passenger_id,survived,pclass,name ,sex,age,sibsp,parch,ticket,fare,cabin,embarked=\	
         read_csv(100,"train.csv",[[0.0],[0.0],[0],[""],[""],[0.0],[0.0],[0.0],[""],[0.0],[""],[""]])
         #convert categorical data
         is_first_class=tf.to_float(tf.equal(pclass,[1]))
         is_second_class=tf.to_float(tf.equal(pclass,[2]))
         is_third_class=tf.to_float(tf.equal(pclass,[3]))
         gender=tf.to_float(tf.equal(sex,["female"]))
         #finally we pack all the features in a single matrix;
         #we then transpose to have a matrix with one example per row and one feature per column
         features=tf.transpose(tf.pack([is_first_class,is_second_class,is_third_class,gender,age]))
         survived=tf.reshape(survived,[100,1])
         return features,survived
     def train(total_loss):
         learning_rate=0.01
         return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)
     def evaluate(sess,X,y):
         predicted=tf.cast(inference(X)>0.5,tf.float32)
         print sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted,Y),tf.float32)))
         
   3.softmax classification
     def loss(x,y):
        return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(combine_inputs(X),y))       
     def inputs():
        sepal_length,sepal_width,petal_length,petal_width,label=\
         read_csv(100,"iris.data",[[0.],[0.],[0.],[0.],[""]])
        label_number=tf.to_int32(tf.argmax(tf.to_int32(tf.pack([tf.equal(label,["Iris_setosa"]),
                                                                tf.equal(label,["Iris_versicolor"]),
                                                                tf.equal(label,["Iris_virginica"]),
                                                                ])),0))
        features=tf.transpose(tf.pack([sepal_length,sepal_width,petal_length,petal_width]))
        return features,label_number
     def evaluate(sess,X,Y):
        predicted=tf.cast(tf.arg_max(inference(X),1),tf.int32)
        print sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted,Y),tf.float32)))
        
  4.Multi-layer Neural Network
     todo...
         
         